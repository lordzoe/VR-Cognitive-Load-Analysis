{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Nested CV for LogisticRegression ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy (outer CV): 0.281 +/- 0.049\n",
      "\n",
      "=== Nested CV for SVM ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy (outer CV): 0.256 +/- 0.014\n",
      "\n",
      "=== Nested CV for LDA ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 21 is smaller than n_iter=50. Running 21 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "24 fits failed out of a total of 63.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 637, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 467, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"c:\\Program Files\\PsychoPy\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 594, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 5 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 637, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 467, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"c:\\Program Files\\PsychoPy\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 594, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 4 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 621, in fit\n",
      "    raise NotImplementedError(\"shrinkage not supported with 'svd' solver.\")\n",
      "NotImplementedError: shrinkage not supported with 'svd' solver.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.21574678 0.21263152        nan        nan 0.20628343 0.20628343\n",
      "        nan 0.21263152        nan        nan 0.20634221 0.20634221\n",
      "        nan 0.23126433 0.23126433        nan 0.21242579 0.21242579\n",
      "        nan 0.19990595 0.19990595]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 21 is smaller than n_iter=50. Running 21 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "24 fits failed out of a total of 63.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 637, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 467, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"c:\\Program Files\\PsychoPy\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 594, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 5 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 637, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 467, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"c:\\Program Files\\PsychoPy\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 594, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 4 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 621, in fit\n",
      "    raise NotImplementedError(\"shrinkage not supported with 'svd' solver.\")\n",
      "NotImplementedError: shrinkage not supported with 'svd' solver.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.24381355 0.24692882        nan        nan 0.27179216 0.27179216\n",
      "        nan 0.24692882        nan        nan 0.2686475  0.2686475\n",
      "        nan 0.284312   0.284312          nan 0.26244636 0.26244636\n",
      "        nan 0.23452654 0.23452654]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 21 is smaller than n_iter=50. Running 21 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "24 fits failed out of a total of 63.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 637, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 467, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"c:\\Program Files\\PsychoPy\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 594, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 5 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 637, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 467, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"c:\\Program Files\\PsychoPy\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 594, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 4 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\discriminant_analysis.py\", line 621, in fit\n",
      "    raise NotImplementedError(\"shrinkage not supported with 'svd' solver.\")\n",
      "NotImplementedError: shrinkage not supported with 'svd' solver.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.2217422  0.21862693        nan        nan 0.21548228 0.21548228\n",
      "        nan 0.21862693        nan        nan 0.21862693 0.21862693\n",
      "        nan 0.20928114 0.20928114        nan 0.21245518 0.21245518\n",
      "        nan 0.19056016 0.19056016]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA accuracy (outer CV): 0.279 +/- 0.039\n",
      "\n",
      "=== Nested CV for RandomForest ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mobile Workstation 3\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest accuracy (outer CV): 0.271 +/- 0.043\n",
      "\n",
      "All results: {'LogisticRegression': (0.28125, 0.04868050602311634), 'SVM': (0.25625000000000003, 0.013501543121683054), 'LDA': (0.2791666666666666, 0.03897559777889522), 'RandomForest': (0.2708333333333333, 0.04340138886666596)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy.stats import loguniform, uniform  # for sampling continuous hyperparams\n",
    "# loguniform ~ for parameters that vary over several orders of magnitude (e.g., C)\n",
    "# uniform     ~ for parameters that vary over a linear scale\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Load your data\n",
    "# ----------------------------------------------------\n",
    "df = pd.read_csv('master.csv')\n",
    "#\n",
    "# The user says we have columns like:\n",
    "#   participant_number, subexperiment_number, time_subexperiment, ...\n",
    "#   feedback_score_subexperiment (the target), ...\n",
    "# We'll drop participant_number, subexperiment_number\n",
    "# We'll keep only the columns of interest\n",
    "\n",
    "use_cols = [\n",
    "    'time_subexperiment',\n",
    "    'accuracy_subexperiment', \n",
    "    'accuracy_total',\n",
    "    'answer_correct_subexperiment',\n",
    "    'answer_incorrect_subexperiment',\n",
    "    'feedback_score_subexperiment',  # target\n",
    "    'trial_duration_1', 'trial_duration_2', 'trial_duration_3', 'trial_duration_4',\n",
    "    'trial_duration_mean',\n",
    "    'performance_subexperiment',\n",
    "    'feedback_score_tutorial_1', 'feedback_score_tutorial_2', 'feedback_score_tutorial_3',\n",
    "    'feedback_score_rest_1',\n",
    "    'O2Hb_highest_peak', 'O2Hb_lowest_peak', 'O2Hb_average_peak', 'O2Hb_difference_peak',\n",
    "    'O2Hb_auc',\n",
    "    'O2Hb_highest_peak_trial_1', 'O2Hb_highest_peak_trial_2', 'O2Hb_highest_peak_trial_3', 'O2Hb_highest_peak_trial_4',\n",
    "    'O2Hb_lowest_peak_trial_1', 'O2Hb_lowest_peak_trial_2', 'O2Hb_lowest_peak_trial_3', 'O2Hb_lowest_peak_trial_4',\n",
    "    'O2Hb_average_peak_trial_1', 'O2Hb_average_peak_trial_2', 'O2Hb_average_peak_trial_3', 'O2Hb_average_peak_trial_4',\n",
    "    'O2Hb_difference_peak_trial_1', 'O2Hb_difference_peak_trial_2', 'O2Hb_difference_peak_trial_3', 'O2Hb_difference_peak_trial_4',\n",
    "    'O2Hb_auc_peak_trial_1', 'O2Hb_auc_peak_trial_2', 'O2Hb_auc_peak_trial_3', 'O2Hb_auc_peak_trial_4'\n",
    "]\n",
    "\n",
    "# Suppose df is your entire dataset:\n",
    "df = df[ ['participant_number','subexperiment_number'] + use_cols ]\n",
    "df = df.drop(['participant_number','subexperiment_number'], axis=1)\n",
    "\n",
    "# Drop any NaNs if needed\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Now define features X, and target y\n",
    "X = df.drop('feedback_score_subexperiment', axis=1)\n",
    "y = df['feedback_score_subexperiment']\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Quick check: classification or regression?\n",
    "# ----------------------------------------------------\n",
    "# If 'feedback_score_subexperiment' is categorical (like discrete classes 1..5),\n",
    "# we do classification. If continuous, switch to regressor versions.\n",
    "\n",
    "# We'll assume it's classification for this example.\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Model Pipelines\n",
    "# ----------------------------------------------------\n",
    "pipeline_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "pipeline_lda = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LinearDiscriminantAnalysis())\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Hyperparameter distributions for RandomizedSearch\n",
    "# ----------------------------------------------------\n",
    "# We use 'loguniform' for parameters that can span orders of magnitude,\n",
    "# e.g. C in logistic regression or SVM, because it can be anywhere from 1e-3 to 1e3.\n",
    "# For RandomForest, we can sample # of estimators from a discrete set, etc.\n",
    "\n",
    "param_dist_lr = {\n",
    "    'clf__C': loguniform(1e-3, 1e3),        # from 0.001 to 1000\n",
    "    'clf__penalty': ['l2'],\n",
    "    'clf__solver': ['lbfgs', 'saga']        # saga can handle L1 but also L2\n",
    "}\n",
    "\n",
    "param_dist_svm = {\n",
    "    'clf__C': loguniform(1e-3, 1e3),\n",
    "    'clf__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'clf__gamma': loguniform(1e-4, 10)      # or 'scale', but let's search explicitly\n",
    "}\n",
    "\n",
    "param_dist_lda = {\n",
    "    'clf__solver': ['svd', 'lsqr', 'eigen'],\n",
    "    # For 'lsqr' or 'eigen', we can optionally search for shrinkage factor\n",
    "    'clf__shrinkage': [None, 'auto', 0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "param_dist_rf = {\n",
    "    'clf__n_estimators': [50, 100, 200, 500],\n",
    "    'clf__max_depth': [None, 5, 10, 20, 50],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 5],\n",
    "    'clf__max_features': ['sqrt', 'log2', None]  # controls feature subsampling\n",
    "}\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Nested Cross-Validation Setup\n",
    "# ----------------------------------------------------\n",
    "# We create an outer StratifiedKFold for the final evaluation.\n",
    "# For each outer fold, we'll do an inner RandomizedSearchCV to select hyperparams.\n",
    "# We'll store the performance from each outer fold and average.\n",
    "\n",
    "N_SPLITS_OUTER = 3  # e.g., 5 outer folds\n",
    "N_SPLITS_INNER = 3  # e.g., 5 inner folds\n",
    "N_ITER_SEARCH = 50  # number of random samples in hyperparameter search\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=N_SPLITS_OUTER, shuffle=True, random_state=42)\n",
    "\n",
    "# We'll define a helper function that does nested CV for a pipeline & param distribution\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def nested_cv_score(pipeline, param_dist, X, y, n_splits_outer, n_splits_inner, n_iter):\n",
    "    \"\"\"\n",
    "    Perform nested CV with given pipeline & param distribution.\n",
    "    Returns list of outer fold scores.\n",
    "    \"\"\"\n",
    "    outer_cv = StratifiedKFold(n_splits=n_splits_outer, shuffle=True, random_state=42)\n",
    "    outer_scores = []\n",
    "\n",
    "    fold_idx = 1\n",
    "    for train_idx, test_idx in outer_cv.split(X, y):\n",
    "        X_train_outer, X_test_outer = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train_outer, y_test_outer = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # Inner cross-validation for hyperparameter tuning\n",
    "        inner_cv = StratifiedKFold(n_splits=n_splits_inner, shuffle=True, random_state=fold_idx)\n",
    "\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_distributions=param_dist,\n",
    "            n_iter=n_iter,\n",
    "            cv=inner_cv,\n",
    "            scoring='accuracy',     # or f1, roc_auc, etc.\n",
    "            random_state=fold_idx,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        random_search.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "        # Best model from inner CV\n",
    "        best_model = random_search.best_estimator_\n",
    "\n",
    "        # Evaluate on the held-out test from the outer fold\n",
    "        y_pred_outer = best_model.predict(X_test_outer)\n",
    "        fold_acc = accuracy_score(y_test_outer, y_pred_outer)\n",
    "        outer_scores.append(fold_acc)\n",
    "        fold_idx += 1\n",
    "    \n",
    "    return outer_scores\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Run nested CV for each of the four models\n",
    "# ----------------------------------------------------\n",
    "models = [\n",
    "    (\"LogisticRegression\", pipeline_lr, param_dist_lr),\n",
    "    (\"SVM\", pipeline_svm, param_dist_svm),\n",
    "    (\"LDA\", pipeline_lda, param_dist_lda),\n",
    "    (\"RandomForest\", pipeline_rf, param_dist_rf),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for name, pipe, params in models:\n",
    "    print(f\"\\n=== Nested CV for {name} ===\")\n",
    "    scores = nested_cv_score(pipe, params, X, y,\n",
    "                             n_splits_outer=N_SPLITS_OUTER,\n",
    "                             n_splits_inner=N_SPLITS_INNER,\n",
    "                             n_iter=N_ITER_SEARCH)\n",
    "    mean_score = np.mean(scores)\n",
    "    std_score = np.std(scores)\n",
    "    print(f\"{name} accuracy (outer CV): {mean_score:.3f} +/- {std_score:.3f}\")\n",
    "    results[name] = (mean_score, std_score)\n",
    "\n",
    "print(\"\\nAll results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
